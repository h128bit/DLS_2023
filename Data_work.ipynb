{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHS65-6Q3NkU",
        "outputId": "0e8b3625-2a85-4cc7-aa80-b3e376536a20"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoD8_e3-2ef2"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/DLS Face recognition/celebA_train_500.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/drive/MyDrive/DLS Face recognition')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm, tqdm_notebook"
      ],
      "metadata": {
        "id": "llrJz3E541wA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1, 2, 3]\n",
        "a += [] + [111]\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHor_tFE2Ceg",
        "outputId": "1f4d86b0-fbf1-4cc6-e9da-d7a03a722de3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 111]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "class CelebADataSet(Dataset):\n",
        "    def __init__(self, ptest=80, pval=5):\n",
        "        \"\"\"\n",
        "        Параметр p определяет какой процент данных будет отдан для тренировочной выборки\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self._path_to_file_name = '/content/drive/MyDrive/DLS Face recognition/celebA_train_500/celebA_imgs'\n",
        "        self._path_to_annot = '/content/drive/MyDrive/DLS Face recognition/celebA_train_500/celebA_anno.txt'\n",
        "\n",
        "        self._table = pd.read_csv(self._path_to_annot, header=None, sep=' ')\n",
        "        self._table.columns = ['File_name', 'Class']\n",
        "\n",
        "        self._len = self._table.shape[0]\n",
        "\n",
        "        # Получаем индексы для разделения данных на train и test\n",
        "        idx = np.random.choice(self._len, self._len, False)\n",
        "        p1 = self._len//100 * ptest\n",
        "        p2 = self._len//100 * (100 - pval)\n",
        "        self.train_idx, self.test_idx, self.val_idx = np.split(idx, [p1, p2])\n",
        "\n",
        "    class _Data(Dataset):\n",
        "        \"\"\"\n",
        "        Класс, который будет подаваться в Dataloader\n",
        "        \"\"\"\n",
        "        def __init__(self, upper, idx, train=True):\n",
        "            super().__init__()\n",
        "            self._upper = upper\n",
        "            self.train = train\n",
        "\n",
        "            self._table = self._upper._table.iloc[idx]\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self._table)\n",
        "\n",
        "        def __getitem__(self, index):\n",
        "            path_to_img = os.path.join(self._upper._path_to_file_name,\n",
        "                                       self._table['File_name'].iloc[index])\n",
        "            image = cv2.cvtColor(cv2.imread(path_to_img),\n",
        "                                 cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            make_transforms = {True: transforms.Compose([transforms.ToTensor(),\n",
        "                                                        transforms.Resize(224, antialias=True),\n",
        "                                                        transforms.RandomAutocontrast(),\n",
        "                                                        transforms.RandomHorizontalFlip(),\n",
        "                                                        transforms.ColorJitter(hue=0.1, saturation=0.1),\n",
        "                                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
        "                              False: transforms.Compose([transforms.ToTensor(),\n",
        "                                                        transforms.Resize(224, antialias=True),\n",
        "                                                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n",
        "\n",
        "            image = make_transforms[self.train](image)\n",
        "            label =  self._table['Class'].iloc[index]\n",
        "\n",
        "            return image, label\n",
        "\n",
        "    def get_train(self):\n",
        "        return self._Data(self, self.train_idx)\n",
        "    def get_test(self):\n",
        "        return self._Data(self, self.test_idx, False)\n",
        "    def get_val(self):\n",
        "        return self._Data(self, self.val_idx, False)\n",
        "    def get_train_and_test(self):\n",
        "        return self.get_train(), self.get_test()"
      ],
      "metadata": {
        "id": "jmvAgjiRE9ZD"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deatech(data):\n",
        "    return data.cpu().numpy()"
      ],
      "metadata": {
        "id": "XQOdjX0TZEGF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_epoch(model, train_loader, loss_fn, optimaizer, DEVICE):\n",
        "    loss_per_epoch = 0\n",
        "    accuracy_per_epoch = 0\n",
        "    processed = 0\n",
        "\n",
        "    log_template = \"\\ntrain loss: {t_loss:0.4f} train acc {t_acc:0.4f}\"\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    with tqdm(desc=\"train\", total=len(train_loader)) as pbar_outer:\n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "\n",
        "            # forward and backward\n",
        "            optimaizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            optimaizer.step()\n",
        "\n",
        "            #statistic\n",
        "            preds = torch.argmax(outputs, 1)\n",
        "            loss_per_epoch += loss.item() * images.size(0)\n",
        "            accuracy_per_epoch += torch.sum(preds == labels.data)\n",
        "            processed += images.size(0)\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            pbar_outer.update(1)\n",
        "            tqdm.write(log_template.format(t_loss=loss_per_epoch/processed, t_acc=accuracy_per_epoch/processed))\n",
        "\n",
        "    loss_per_epoch = loss_per_epoch / processed\n",
        "    accuracy_per_epoch = accuracy_per_epoch / processed\n",
        "    torch.cuda.empty_cache()\n",
        "    return loss_per_epoch, accuracy_per_epoch"
      ],
      "metadata": {
        "id": "4_SHinSSU2IS"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_epoch(model, test_loader, loss_fn, DEVICE):\n",
        "    loss_per_epoch = 0\n",
        "    accuracy_per_epoch = 0\n",
        "    processed = 0\n",
        "\n",
        "    model.eval()\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        logits = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            logits.append(outputs)\n",
        "\n",
        "            #statistic\n",
        "            processed += images.shape[0]\n",
        "            loss_per_epoch += loss.item()\n",
        "\n",
        "            pred = torch.nn.functional.softmax(torch.cat(logits), dim=-1).to(DEVICE)\n",
        "            accuracy_per_epoch += torch.sum(torch.argmax(pred, 1) == labels.data)\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    loss_per_epoch = loss_per_epoch / processed\n",
        "    accuracy_per_epoch = accuracy_per_epoch / processed\n",
        "    torch.cuda.empty_cache()\n",
        "    return loss_per_epoch, accuracy_per_epoch"
      ],
      "metadata": {
        "id": "x_3unHT5ZTMx"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, test_loader, num_epoch, loss_fn, optimaizer, scheduler, DEVICE):\n",
        "    history = {'train loss':[], 'test loss': [],\n",
        "               'train accuracy': [], 'test accuracy': []}\n",
        "\n",
        "    log_template = \"\\nEpoch {ep:03d} train loss: {t_loss:0.4f} \\\n",
        "    test loss {v_loss:0.4f} train acc {t_acc:0.4f} test acc {v_acc:0.4f}\"\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    with tqdm(desc=\"epoch\", total=num_epoch) as pbar_outer:\n",
        "        for epoch in range(num_epoch):\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            train_loss, train_accuracy = fit_epoch(model, train_loader, loss_fn, optimaizer, DEVICE)\n",
        "            test_loss, test_accuracy = test_epoch(model, test_loader, loss_fn, DEVICE)\n",
        "\n",
        "            history['train loss'].append(train_loss)\n",
        "            history['test loss'].append(test_loss)\n",
        "            history['train accuracy'].append(train_accuracy)\n",
        "            history['test accuracy'].append(test_accuracy)\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "            pbar_outer.update(1)\n",
        "            tqdm.write(log_template.format(ep=epoch, t_loss=train_loss,\\\n",
        "                                            v_loss=test_loss, t_acc=train_accuracy, v_acc=test_accuracy))\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    return history"
      ],
      "metadata": {
        "id": "3GrgTxd7bFI-"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import mobilenet_v3_large, MobileNet_V3_Large_Weights, resnet18\n",
        "\n",
        "model = mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.IMAGENET1K_V2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfc61wYL4Zxk",
        "outputId": "8414677d-a0da-49ee-bf68-d4878c679f88"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-5c1a4163.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-5c1a4163.pth\n",
            "100%|██████████| 21.1M/21.1M [00:00<00:00, 26.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "celebA = CelebADataSet(ptest=85)\n",
        "train, test = celebA.get_train_and_test()\n",
        "\n",
        "batch_size = 256\n",
        "num_workers = 2\n",
        "\n",
        "train_data = DataLoader(train, batch_size=batch_size, num_workers=num_workers)\n",
        "test_data = DataLoader(test, batch_size=batch_size, num_workers=num_workers)"
      ],
      "metadata": {
        "id": "yGVmxrApOSvo"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_CLASSES = 500\n",
        "\n",
        "in_features = model.classifier[-1].in_features\n",
        "model.classifier[-1] = torch.nn.Linear(in_features, N_CLASSES)"
      ],
      "metadata": {
        "id": "opux8NBjUQnH"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters())\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 3, 0.5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(DEVICE)"
      ],
      "metadata": {
        "id": "W0GGsH7Yft9B"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "num_epoch = 50\n",
        "history = train_model(model, train_data, test_data, num_epoch, loss_fn, optimizer, scheduler, DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjxj4MEwx0Kx",
        "outputId": "3de54d20-98c5-450c-c296-0f1471babd48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:   0%|          | 0/50 [00:00<?, ?it/s]\n",
            "train:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "train:   2%|▎         | 1/40 [03:29<2:16:21, 209.79s/it]\u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [03:29<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 6.2223 train acc 0.0039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:   5%|▌         | 2/40 [03:30<55:08, 87.07s/it]   \u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [03:30<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 6.2148 train acc 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcacce3fc70>\n",
            "Traceback (most recent call last):\n",
            "self._shutdown_workers()  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    \n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    \n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "if w.is_alive():    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcacce3fc70>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcacce3fc70>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcacce3fc70>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcacce3fc70>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcacce3fc70>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():    \n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "\n",
            "train:   8%|▊         | 3/40 [07:06<1:29:47, 145.61s/it]\u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [07:06<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 6.2109 train acc 0.0039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  10%|█         | 4/40 [07:07<53:09, 88.59s/it]   \u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [07:07<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 6.2045 train acc 0.0078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  12%|█▎        | 5/40 [10:37<1:17:08, 132.23s/it]\u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [10:37<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 6.1988 train acc 0.0102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  15%|█▌        | 6/40 [10:38<49:40, 87.67s/it]   \u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [10:38<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 6.1922 train acc 0.0098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  18%|█▊        | 7/40 [14:16<1:11:45, 130.47s/it]\u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [14:16<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 6.1836 train acc 0.0100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  20%|██        | 8/40 [14:17<47:38, 89.32s/it]   \u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [14:18<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 6.1788 train acc 0.0098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  22%|██▎       | 9/40 [17:48<1:05:44, 127.24s/it]\u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [17:48<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 6.1682 train acc 0.0104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  25%|██▌       | 10/40 [17:49<44:09, 88.31s/it]  \u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [17:49<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 6.1546 train acc 0.0105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  28%|██▊       | 11/40 [21:24<1:01:19, 126.87s/it]\u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [21:24<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 6.1384 train acc 0.0124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  30%|███       | 12/40 [21:25<41:21, 88.63s/it]   \u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [21:25<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 6.1200 train acc 0.0143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  32%|███▎      | 13/40 [24:57<56:44, 126.09s/it]\u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [24:57<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 6.0967 train acc 0.0174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  35%|███▌      | 14/40 [24:58<38:17, 88.38s/it] \u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [24:58<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 6.0702 train acc 0.0187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  38%|███▊      | 15/40 [28:30<52:21, 125.66s/it]\u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [28:30<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 6.0403 train acc 0.0198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  40%|████      | 16/40 [28:31<35:16, 88.19s/it] \u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [28:32<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 6.0152 train acc 0.0208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  42%|████▎     | 17/40 [31:59<47:32, 124.02s/it]\u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [31:59<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 5.9835 train acc 0.0230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  45%|████▌     | 18/40 [32:00<31:56, 87.10s/it] \u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [32:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 5.9462 train acc 0.0247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  48%|████▊     | 19/40 [35:33<43:44, 124.96s/it]\u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [35:33<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 5.9027 train acc 0.0278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  50%|█████     | 20/40 [35:34<29:16, 87.81s/it] \u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [35:34<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 5.8668 train acc 0.0289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  52%|█████▎    | 21/40 [39:04<39:24, 124.42s/it]\u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [39:04<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 5.8311 train acc 0.0299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  55%|█████▌    | 22/40 [39:05<26:13, 87.43s/it] \u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [39:05<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 5.7901 train acc 0.0309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  57%|█████▊    | 23/40 [42:38<35:27, 125.14s/it]\u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [42:38<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 5.7523 train acc 0.0324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  60%|██████    | 24/40 [42:40<23:27, 87.94s/it] \u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [42:40<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 5.7127 train acc 0.0348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  62%|██████▎   | 25/40 [46:13<31:23, 125.59s/it]\u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [46:13<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 5.6692 train acc 0.0375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  65%|██████▌   | 26/40 [46:14<20:35, 88.26s/it] \u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [46:14<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 5.6285 train acc 0.0397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  68%|██████▊   | 27/40 [49:45<27:05, 125.05s/it]\u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [49:45<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 5.5848 train acc 0.0440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train:  70%|███████   | 28/40 [49:46<17:34, 87.90s/it] \u001b[A\n",
            "\n",
            "epoch:   0%|          | 0/50 [49:46<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train loss: 5.5521 train acc 0.0458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "val_data = DataLoader(celebA.get_val(), batch_size=batch_size)\n",
        "\n",
        "val_loss = 0\n",
        "val_acc = 0\n",
        "\n",
        "logits = []\n",
        "labels_ = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_data:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        outputs = model(images).cpu()\n",
        "        logits.append(outputs)\n",
        "        labels_.extend([*labels])\n",
        "\n",
        "probs = torch.nn.functional.softmax(torch.cat(logits), dim=-1).numpy()"
      ],
      "metadata": {
        "id": "97YEGs1NhYke"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob_ = torch.argmax(torch.Tensor(probs), 1).numpy()\n",
        "labels_ = torch.Tensor(labels_).numpy()\n",
        "\n",
        "val_accuracy = np.sum(labels_ == prob_)/len(labels_)\n",
        "val_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjYL1Gokn7Dk",
        "outputId": "20bb6f77-4250-4688-ada5-f608860f8392"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6923076923076923"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_save_model_state = '/content/drive/MyDrive/DLS Face recognition'\n",
        "torch.save(model.state_dict(), path_to_save_model_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "U-zqBMMYlu9G",
        "outputId": "f9cb4df0-ecb0-4b5b-d6d2-ee26d449cd78"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "File /content/drive/MyDrive/DLS Face recognition cannot be opened.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-fdf42b8b5a7a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath_to_save_model_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/DLS Face recognition'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_save_model_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_disable_byteorder_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_zipfile_writer_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: File /content/drive/MyDrive/DLS Face recognition cannot be opened."
          ]
        }
      ]
    }
  ]
}